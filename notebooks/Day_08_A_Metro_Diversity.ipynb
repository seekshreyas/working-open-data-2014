{
 "metadata": {
  "name": "",
  "signature": "sha256:f816c2b9e658ead0cab8a896dab2330d9cacd5cd6b3e06ec3bab2563058988f0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Exercise"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this exercise, reproduce some of the findings from [What Makes Houston the Next Great American City? | Travel | Smithsonian](http://www.smithsonianmag.com/travel/what-makes-houston-the-next-great-american-city-4870584/), specifically the calculation represented in\n",
      "\n",
      "![Alt text](http://thumbs.media.smithsonianmag.com//filer/Houston-diversity-3.jpg__600x0_q85_upscale.jpg \"Optional title\")\n",
      "\n",
      "whose caption is\n",
      "\n",
      "<blockquote>To assess the parity of the four major U.S. ethnic and racial groups, Rice University researchers used a scale called the Entropy Index. It ranges from 0 (a population has just one group) to 1 (all groups are equivalent). Edging New York for the most balanced diversity, Houston had an Entropy Index of 0.874 (orange bar).</blockquote>\n",
      "\n",
      "The research report by *Smithsonian Magazine* is\n",
      "[Houston Region Grows More Racially/Ethnically Diverse, With Small Declines in Segregation: A Joint Report Analyzing Census Data from 1990, 2000, and 2010](http://kinder.rice.edu/uploadedFiles/Urban_Research_Center/Media/Houston%20Region%20Grows%20More%20Ethnically%20Diverse%202-13.pdf) by the Kinder Institute for Urban Research & the Hobby Center for the Study of Texas.  \n",
      "\n",
      "In the report, you'll find the following quotes:\n",
      "\n",
      "<blockquote>How does Houston\u2019s racial/ethnic diversity compare to the racial/ethnic\n",
      "diversity of other large metropolitan areas? The Houston metropolitan\n",
      "area is the most racially/ethnically diverse.</blockquote>\n",
      "\n",
      "....\n",
      "\n",
      "<blockquote>Houston is one of the most racially/ethnically diverse metropolitan\n",
      "areas in the nation as well. *It is the most diverse of the 10 largest\n",
      "U.S. metropolitan areas.* [emphasis mine] Unlike the other large metropolitan areas, all\n",
      "four major racial/ethnic groups have substantial representation in\n",
      "Houston with Latinos and Anglos occupying roughly equal shares of the\n",
      "population.</blockquote>\n",
      "\n",
      "....\n",
      "\n",
      "<blockquote>Houston has the highest entropy score of the 10 largest metropolitan\n",
      "areas, 0.874. New York is a close second with a score of 0.872.</blockquote>\n",
      "\n",
      "....\n",
      "\n",
      "Your task is:\n",
      "\n",
      "1. Tabulate all the metropolian/micropolitan statistical areas.  Remember that you have to group various entities that show up separately in the Census API but which belong to the same area.  You should find 942 metropolitan/micropolitan statistical areas in the 2010 Census.\n",
      "\n",
      "1. Calculate the normalized Shannon index (`entropy5`) using the categories of White, Black, Hispanic, Asian, and Other as outlined in the [Day_07_G_Calculating_Diversity notebook](http://nbviewer.ipython.org/github/rdhyee/working-open-data-2014/blob/master/notebooks/Day_07_G_Calculating_Diversity.ipynb#Converting-to-Racial-Dot-Map-Categories) \n",
      "\n",
      "1. Calculate the normalized Shannon index (`entropy4`) by not considering the Other category.  In other words, assume that the the total population is the sum of White, Black, Hispanic, and Asian.\n",
      "\n",
      "1. Figure out how exactly the entropy score was calculated in the report from Rice University. Since you'll find that the entropy score reported matches neither `entropy5` nor `entropy4`, you'll need to play around with the entropy calculation to figure how to use 4 categories to get the score for Houston to come out to \"0.874\" and that for NYC to be \"0.872\".  [I **think** I've done so and get 0.873618 and \n",
      "0.872729 respectively.]\n",
      "\n",
      "1. Add a calculation of the [Gini-Simpson diversity index](https://en.wikipedia.org/wiki/Diversity_index#Gini.E2.80.93Simpson_index) using the five categories of White, Black, Hispanic, Asian, and Other.\n",
      "\n",
      "1. Note where the Bay Area stands in terms of the diversity index.\n",
      "\n",
      "For bonus points:\n",
      "\n",
      "* make a bar chart in the style used in the Smithsonian Magazine\n",
      "\n",
      "Deliverable:\n",
      "\n",
      "1. You will need to upload your notebook to a gist and render the notebook in nbviewer and then enter the nbviewer URL (e.g., http://nbviewer.ipython.org/gist/rdhyee/60b6c0b0aad7fd531938)\n",
      "2. On bCourses, upload the CSV version of your `msas_df`.\n",
      "\n",
      "**HAVE FUN: ASK QUESTIONS AND WORK TOGETHER**"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Constraints"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below is testing code to help make sure you are on the right track.  A key assumption made here is that you will end up with a Pandas DataFrame called `msas_df`, indexed by the FIPS code of a metropolitan/micropolitan area (e.g., Houston's code is 26420) and with the the following columns:\n",
      "\n",
      "* Total\n",
      "* White\n",
      "* Black\n",
      "* Hispanic\n",
      "* Asian\n",
      "* Other\n",
      "* p_White\n",
      "* p_Black\n",
      "* p_Hispanic\n",
      "* p_Asian\n",
      "* p_Other\n",
      "* entropy4\n",
      "* entropy5\n",
      "* entropy_rice\n",
      "* gini_simpson\n",
      "\n",
      "You should have 942 rows, one for each MSA.  You can compare your results for `entropy5`, `entropy_rice` with mine."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# FILL IN WITH YOUR CODE\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from pandas import DataFrame, Series, Index\n",
      "import pandas as pd\n",
      "\n",
      "import census \n",
      "import us\n",
      "import settings\n",
      "\n",
      "from itertools import islice\n",
      "\n",
      "c = census.Census(key=settings.CENSUS_KEY)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def msas(variables=\"NAME\"):\n",
      "    \n",
      "     for state in us.STATES:\n",
      "        geo = {'for':'metropolitan statistical area/micropolitan statistical area:*', \n",
      "               'in':'state:{state_fips}'.format(state_fips=state.fips)\n",
      "               }\n",
      "    \n",
      "        for msa in c.sf1.get(variables, geo=geo):\n",
      "            yield msa"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Other useful functions imported from Raymond's notebook\n",
      "\n",
      "from __future__ import division\n",
      "import time\n",
      "\n",
      "def P005_range(n0,n1): \n",
      "    return tuple(('P005'+ \"{i:04d}\".format(i=i) for i in xrange(n0,n1)))\n",
      "\n",
      "P005_vars = P005_range(1,18)\n",
      "P005_vars_str = \",\".join(P005_vars)\n",
      "P005_vars_with_name = ['NAME'] + list(P005_vars)\n",
      "# P005_vars_with_name = list(P005_vars)\n",
      "\n",
      "\n",
      "\n",
      "# http://manishamde.github.io/blog/2013/03/07/pandas-and-python-top-10/#create\n",
      "\n",
      "## p_White\n",
      "# p_Black\n",
      "# p_Hispanic\n",
      "# p_Asian\n",
      "# p_Other\n",
      "\n",
      "def convert_to_rdotmap(row):\n",
      "    \"\"\"takes the P005 variables and maps to a series with White, Black, Asian, Hispanic, Other\n",
      "    Total and Name\"\"\"\n",
      "    \n",
      "    total = int(row['P0050001'])\n",
      "    white = int(row['P0050003'])\n",
      "    black = int(row['P0050004'])\n",
      "    asian = int(row['P0050006'])\n",
      "    hispanic = int(row['P0050010'])\n",
      "    other = total - (white + black + asian + hispanic)\n",
      "    name = row['NAME']\n",
      "    metro = row['metropolitan statistical area/micropolitan statistical area']\n",
      "\n",
      "    return pd.Series({'Total':total,\n",
      "                      'White':white,\n",
      "                      'Black':black,\n",
      "                      'Asian':asian,\n",
      "                      'Hispanic':hispanic,\n",
      "                      'Other': other,\n",
      "                      'Name': name,\n",
      "                      'Metro': metro\n",
      "#                       'p_White': white/float(total),\n",
      "#                       'p_Black': black/float(total),\n",
      "#                       'p_Hispanic': hispanic/float(total),\n",
      "#                       'p_Asian' : asian/float(total),\n",
      "#                       'p_Other' : other/float(total)\n",
      "                      }, index=['Name', 'Metro', 'Total', 'White', 'Black', 'Hispanic', 'Asian', 'Other'])\n",
      "\n",
      "\n",
      "def normalize(s):\n",
      "    \"\"\"take a Series and divide each item by the sum so that the new series adds up to 1.0\"\"\"\n",
      "    total = np.sum(s)\n",
      "    return s.astype('float') / total\n",
      "\n",
      "\n",
      "def entropy(series):\n",
      "    \"\"\"Normalized Shannon Index\"\"\"\n",
      "    # a series in which all the entries are equal should result in normalized entropy of 1.0\n",
      "    \n",
      "    # eliminate 0s\n",
      "    series1 = series[series!=0]\n",
      "    \n",
      "    series1.astype('int')\n",
      "\n",
      "    # if len(series) < 2 (i.e., 0 or 1) then return 0\n",
      "    \n",
      "    if len(series1) > 1:\n",
      "        # calculate the maximum possible entropy for given length of input series\n",
      "        max_s = -np.log(1.0/len(series1))\n",
      "    \n",
      "        total = float(sum(series1))\n",
      "        p = series1.astype('float')/float(total)\n",
      "        return float(sum(-p*np.log(p))/max_s)\n",
      "    else:\n",
      "        return 0.0\n",
      "\n",
      "    \n",
      "def convert_P005_to_int(df):\n",
      "    # do conversion in place\n",
      "    df[list(P005_vars)] = df[list(P005_vars)].astype('int')\n",
      "    return df\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "# Gini-Simpson Index\n",
      "###\n",
      "def gini_simpson(series):\n",
      "      # eliminate 0s\n",
      "    series1 = series[series!=0]\n",
      "    series1.astype('float')\n",
      "    \n",
      "#     max_s = -np.log(1.0/5)\n",
      "    \n",
      "    # if len(series) < 2 (i.e., 0 or 1) then return 0\n",
      "    simpson = 0.0\n",
      "    \n",
      "    \n",
      "#     print series1.head()\n",
      "    \n",
      "    if len(series1) > 1:\n",
      "        # calculate the maximum possible entropy for given length of input series\n",
      "        for i in series1:\n",
      "#             if i > 1:\n",
      "#             print i, type(i)\n",
      "            simpson += (float(i)**2)\n",
      "        \n",
      "#         print simpson\n",
      "        return 1-simpson\n",
      "    else:\n",
      "        return 0.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def frac(series):\n",
      "#     print series\n",
      "    return series[0]/float(series[1])\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "# Entropy-Rice\n",
      "###\n",
      "def entropy_rice(series):\n",
      "    series1 = series[series!=0]\n",
      "    \n",
      "    max_s = -np.log(1.0/5)\n",
      "    \n",
      "    # if len(series) < 2 (i.e., 0 or 1) then return 0\n",
      "    entropy_rice= 0.0\n",
      "    \n",
      "    \n",
      "    if len(series) > 1:\n",
      "        # calculate the maximum possible entropy for given length of input series\n",
      "        for i in series1:\n",
      "            entropy_rice += -i*np.log(i)\n",
      "        \n",
      "        return entropy_rice/max_s\n",
      "    else:\n",
      "        return 0.0\n",
      "\n",
      "\n",
      "def diversity(r):\n",
      "\n",
      "    \"\"\"Returns a DataFrame with the following columns\n",
      "    \"\"\"\n",
      "    df = DataFrame(r)\n",
      "    df = convert_P005_to_int(df)\n",
      "    \n",
      "    # df[list(P005_vars)] = df[list(P005_vars)].astype('int')\n",
      "    df1_ungrouped = df.apply(convert_to_rdotmap, axis=1)\n",
      "    \n",
      "    \n",
      "    df1 = df1_ungrouped.groupby('Name').sum()\n",
      "    \n",
      "    df1['p_Asian'] = df1[['Asian','Total']].apply(frac,axis=1)\n",
      "    df1['p_Black'] = df1[['Black', 'Total']].apply(frac,axis=1)\n",
      "    df1['p_Hispanic'] = df1[['Hispanic', 'Total']].apply(frac,axis=1)\n",
      "    df1['p_White'] = df1[['White', 'Total']].apply(frac,axis=1)\n",
      "    df1['p_Other'] = df1[['Other', 'Total']].apply(frac,axis=1)\n",
      "    \n",
      "    \n",
      "    df1['entropy5'] = df1[['Asian','Black','Hispanic','White','Other']].apply(entropy,axis=1)\n",
      "    df1['entropy4'] = df1[['Asian','Black','Hispanic','White']].apply(entropy,axis=1)\n",
      "    df1['entropy_rice'] = df1[['p_Asian','p_Black','p_Hispanic','p_White','p_Other']].apply(entropy_rice,axis=1)\n",
      "    df1['gini_simpson'] = df1[['p_Asian','p_Black','p_Hispanic','p_White','p_Other']].apply(gini_simpson,axis=1)\n",
      "    \n",
      "    \n",
      "    \n",
      "    return df1\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r=list(msas(P005_vars_with_name))\n",
      "msas_df = diversity(r)\n",
      "# msas_df.astype('int')\n",
      "\n",
      "msas_df.sort(columns=['entropy4'], ascending=False).head()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Total</th>\n",
        "      <th>White</th>\n",
        "      <th>Black</th>\n",
        "      <th>Hispanic</th>\n",
        "      <th>Asian</th>\n",
        "      <th>Other</th>\n",
        "      <th>p_Asian</th>\n",
        "      <th>p_Black</th>\n",
        "      <th>p_Hispanic</th>\n",
        "      <th>p_White</th>\n",
        "      <th>p_Other</th>\n",
        "      <th>entropy5</th>\n",
        "      <th>entropy4</th>\n",
        "      <th>entropy_rice</th>\n",
        "      <th>gini_simpson</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Name</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Vallejo-Fairfield, CA Metro Area</th>\n",
        "      <td>   413344</td>\n",
        "      <td>  168628</td>\n",
        "      <td>   58743</td>\n",
        "      <td>   99356</td>\n",
        "      <td>   59027</td>\n",
        "      <td>  27590</td>\n",
        "      <td> 0.142804</td>\n",
        "      <td> 0.142116</td>\n",
        "      <td> 0.240371</td>\n",
        "      <td> 0.407960</td>\n",
        "      <td> 0.066748</td>\n",
        "      <td> 0.897416</td>\n",
        "      <td> 0.926901</td>\n",
        "      <td> 0.897416</td>\n",
        "      <td> 0.730745</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>San Francisco-Oakland-Fremont, CA Metro Area</th>\n",
        "      <td>  4335391</td>\n",
        "      <td> 1840372</td>\n",
        "      <td>  349895</td>\n",
        "      <td>  938794</td>\n",
        "      <td>  994616</td>\n",
        "      <td> 211714</td>\n",
        "      <td> 0.229418</td>\n",
        "      <td> 0.080707</td>\n",
        "      <td> 0.216542</td>\n",
        "      <td> 0.424500</td>\n",
        "      <td> 0.048834</td>\n",
        "      <td> 0.859532</td>\n",
        "      <td> 0.901183</td>\n",
        "      <td> 0.859532</td>\n",
        "      <td> 0.711379</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>New York-Northern New Jersey-Long Island, NY-NJ-PA Metro Area (part)</th>\n",
        "      <td> 18897109</td>\n",
        "      <td> 9233812</td>\n",
        "      <td> 3044096</td>\n",
        "      <td> 4327560</td>\n",
        "      <td> 1860840</td>\n",
        "      <td> 430801</td>\n",
        "      <td> 0.098472</td>\n",
        "      <td> 0.161088</td>\n",
        "      <td> 0.229006</td>\n",
        "      <td> 0.488636</td>\n",
        "      <td> 0.022797</td>\n",
        "      <td> 0.805286</td>\n",
        "      <td> 0.876454</td>\n",
        "      <td> 0.805286</td>\n",
        "      <td> 0.672625</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Houston-Sugar Land-Baytown, TX Metro Area</th>\n",
        "      <td>  5946800</td>\n",
        "      <td> 2360472</td>\n",
        "      <td>  998883</td>\n",
        "      <td> 2099412</td>\n",
        "      <td>  384596</td>\n",
        "      <td> 103437</td>\n",
        "      <td> 0.064673</td>\n",
        "      <td> 0.167970</td>\n",
        "      <td> 0.353032</td>\n",
        "      <td> 0.396931</td>\n",
        "      <td> 0.017394</td>\n",
        "      <td> 0.796281</td>\n",
        "      <td> 0.876425</td>\n",
        "      <td> 0.796281</td>\n",
        "      <td> 0.685115</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Stockton, CA Metro Area</th>\n",
        "      <td>   685306</td>\n",
        "      <td>  245919</td>\n",
        "      <td>   48540</td>\n",
        "      <td>  266341</td>\n",
        "      <td>   94547</td>\n",
        "      <td>  29959</td>\n",
        "      <td> 0.137963</td>\n",
        "      <td> 0.070830</td>\n",
        "      <td> 0.388645</td>\n",
        "      <td> 0.358846</td>\n",
        "      <td> 0.043716</td>\n",
        "      <td> 0.828052</td>\n",
        "      <td> 0.869824</td>\n",
        "      <td> 0.828052</td>\n",
        "      <td> 0.694223</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 15 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "                                                                         Total  \\\n",
        "Name                                                                             \n",
        "Vallejo-Fairfield, CA Metro Area                                        413344   \n",
        "San Francisco-Oakland-Fremont, CA Metro Area                           4335391   \n",
        "New York-Northern New Jersey-Long Island, NY-NJ-PA Metro Area (part)  18897109   \n",
        "Houston-Sugar Land-Baytown, TX Metro Area                              5946800   \n",
        "Stockton, CA Metro Area                                                 685306   \n",
        "\n",
        "                                                                        White  \\\n",
        "Name                                                                            \n",
        "Vallejo-Fairfield, CA Metro Area                                       168628   \n",
        "San Francisco-Oakland-Fremont, CA Metro Area                          1840372   \n",
        "New York-Northern New Jersey-Long Island, NY-NJ-PA Metro Area (part)  9233812   \n",
        "Houston-Sugar Land-Baytown, TX Metro Area                             2360472   \n",
        "Stockton, CA Metro Area                                                245919   \n",
        "\n",
        "                                                                        Black  \\\n",
        "Name                                                                            \n",
        "Vallejo-Fairfield, CA Metro Area                                        58743   \n",
        "San Francisco-Oakland-Fremont, CA Metro Area                           349895   \n",
        "New York-Northern New Jersey-Long Island, NY-NJ-PA Metro Area (part)  3044096   \n",
        "Houston-Sugar Land-Baytown, TX Metro Area                              998883   \n",
        "Stockton, CA Metro Area                                                 48540   \n",
        "\n",
        "                                                                      Hispanic  \\\n",
        "Name                                                                             \n",
        "Vallejo-Fairfield, CA Metro Area                                         99356   \n",
        "San Francisco-Oakland-Fremont, CA Metro Area                            938794   \n",
        "New York-Northern New Jersey-Long Island, NY-NJ-PA Metro Area (part)   4327560   \n",
        "Houston-Sugar Land-Baytown, TX Metro Area                              2099412   \n",
        "Stockton, CA Metro Area                                                 266341   \n",
        "\n",
        "                                                                        Asian  \\\n",
        "Name                                                                            \n",
        "Vallejo-Fairfield, CA Metro Area                                        59027   \n",
        "San Francisco-Oakland-Fremont, CA Metro Area                           994616   \n",
        "New York-Northern New Jersey-Long Island, NY-NJ-PA Metro Area (part)  1860840   \n",
        "Houston-Sugar Land-Baytown, TX Metro Area                              384596   \n",
        "Stockton, CA Metro Area                                                 94547   \n",
        "\n",
        "                                                                       Other  \\\n",
        "Name                                                                           \n",
        "Vallejo-Fairfield, CA Metro Area                                       27590   \n",
        "San Francisco-Oakland-Fremont, CA Metro Area                          211714   \n",
        "New York-Northern New Jersey-Long Island, NY-NJ-PA Metro Area (part)  430801   \n",
        "Houston-Sugar Land-Baytown, TX Metro Area                             103437   \n",
        "Stockton, CA Metro Area                                                29959   \n",
        "\n",
        "                                                                       p_Asian  \\\n",
        "Name                                                                             \n",
        "Vallejo-Fairfield, CA Metro Area                                      0.142804   \n",
        "San Francisco-Oakland-Fremont, CA Metro Area                          0.229418   \n",
        "New York-Northern New Jersey-Long Island, NY-NJ-PA Metro Area (part)  0.098472   \n",
        "Houston-Sugar Land-Baytown, TX Metro Area                             0.064673   \n",
        "Stockton, CA Metro Area                                               0.137963   \n",
        "\n",
        "                                                                       p_Black  \\\n",
        "Name                                                                             \n",
        "Vallejo-Fairfield, CA Metro Area                                      0.142116   \n",
        "San Francisco-Oakland-Fremont, CA Metro Area                          0.080707   \n",
        "New York-Northern New Jersey-Long Island, NY-NJ-PA Metro Area (part)  0.161088   \n",
        "Houston-Sugar Land-Baytown, TX Metro Area                             0.167970   \n",
        "Stockton, CA Metro Area                                               0.070830   \n",
        "\n",
        "                                                                      p_Hispanic  \\\n",
        "Name                                                                               \n",
        "Vallejo-Fairfield, CA Metro Area                                        0.240371   \n",
        "San Francisco-Oakland-Fremont, CA Metro Area                            0.216542   \n",
        "New York-Northern New Jersey-Long Island, NY-NJ-PA Metro Area (part)    0.229006   \n",
        "Houston-Sugar Land-Baytown, TX Metro Area                               0.353032   \n",
        "Stockton, CA Metro Area                                                 0.388645   \n",
        "\n",
        "                                                                       p_White  \\\n",
        "Name                                                                             \n",
        "Vallejo-Fairfield, CA Metro Area                                      0.407960   \n",
        "San Francisco-Oakland-Fremont, CA Metro Area                          0.424500   \n",
        "New York-Northern New Jersey-Long Island, NY-NJ-PA Metro Area (part)  0.488636   \n",
        "Houston-Sugar Land-Baytown, TX Metro Area                             0.396931   \n",
        "Stockton, CA Metro Area                                               0.358846   \n",
        "\n",
        "                                                                       p_Other  \\\n",
        "Name                                                                             \n",
        "Vallejo-Fairfield, CA Metro Area                                      0.066748   \n",
        "San Francisco-Oakland-Fremont, CA Metro Area                          0.048834   \n",
        "New York-Northern New Jersey-Long Island, NY-NJ-PA Metro Area (part)  0.022797   \n",
        "Houston-Sugar Land-Baytown, TX Metro Area                             0.017394   \n",
        "Stockton, CA Metro Area                                               0.043716   \n",
        "\n",
        "                                                                      entropy5  \\\n",
        "Name                                                                             \n",
        "Vallejo-Fairfield, CA Metro Area                                      0.897416   \n",
        "San Francisco-Oakland-Fremont, CA Metro Area                          0.859532   \n",
        "New York-Northern New Jersey-Long Island, NY-NJ-PA Metro Area (part)  0.805286   \n",
        "Houston-Sugar Land-Baytown, TX Metro Area                             0.796281   \n",
        "Stockton, CA Metro Area                                               0.828052   \n",
        "\n",
        "                                                                      entropy4  \\\n",
        "Name                                                                             \n",
        "Vallejo-Fairfield, CA Metro Area                                      0.926901   \n",
        "San Francisco-Oakland-Fremont, CA Metro Area                          0.901183   \n",
        "New York-Northern New Jersey-Long Island, NY-NJ-PA Metro Area (part)  0.876454   \n",
        "Houston-Sugar Land-Baytown, TX Metro Area                             0.876425   \n",
        "Stockton, CA Metro Area                                               0.869824   \n",
        "\n",
        "                                                                      entropy_rice  \\\n",
        "Name                                                                                 \n",
        "Vallejo-Fairfield, CA Metro Area                                          0.897416   \n",
        "San Francisco-Oakland-Fremont, CA Metro Area                              0.859532   \n",
        "New York-Northern New Jersey-Long Island, NY-NJ-PA Metro Area (part)      0.805286   \n",
        "Houston-Sugar Land-Baytown, TX Metro Area                                 0.796281   \n",
        "Stockton, CA Metro Area                                                   0.828052   \n",
        "\n",
        "                                                                      gini_simpson  \n",
        "Name                                                                                \n",
        "Vallejo-Fairfield, CA Metro Area                                          0.730745  \n",
        "San Francisco-Oakland-Fremont, CA Metro Area                              0.711379  \n",
        "New York-Northern New Jersey-Long Island, NY-NJ-PA Metro Area (part)      0.672625  \n",
        "Houston-Sugar Land-Baytown, TX Metro Area                                 0.685115  \n",
        "Stockton, CA Metro Area                                                   0.694223  \n",
        "\n",
        "[5 rows x 15 columns]"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "msas_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Total</th>\n",
        "      <th>White</th>\n",
        "      <th>Black</th>\n",
        "      <th>Hispanic</th>\n",
        "      <th>Asian</th>\n",
        "      <th>Other</th>\n",
        "      <th>p_Asian</th>\n",
        "      <th>p_Black</th>\n",
        "      <th>p_Hispanic</th>\n",
        "      <th>p_White</th>\n",
        "      <th>p_Other</th>\n",
        "      <th>entropy5</th>\n",
        "      <th>entropy4</th>\n",
        "      <th>entropy_rice</th>\n",
        "      <th>gini_simpson</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Name</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Abbeville, LA Micro Area</th>\n",
        "      <td>  57999</td>\n",
        "      <td>  46305</td>\n",
        "      <td>  8246</td>\n",
        "      <td>  1381</td>\n",
        "      <td> 1148</td>\n",
        "      <td>  919</td>\n",
        "      <td> 0.019793</td>\n",
        "      <td> 0.142175</td>\n",
        "      <td> 0.023811</td>\n",
        "      <td> 0.798376</td>\n",
        "      <td> 0.015845</td>\n",
        "      <td> 0.428364</td>\n",
        "      <td> 0.445662</td>\n",
        "      <td> 0.428364</td>\n",
        "      <td> 0.341173</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Aberdeen, SD Micro Area</th>\n",
        "      <td>  40602</td>\n",
        "      <td>  37774</td>\n",
        "      <td>   192</td>\n",
        "      <td>   554</td>\n",
        "      <td>  358</td>\n",
        "      <td> 1724</td>\n",
        "      <td> 0.008817</td>\n",
        "      <td> 0.004729</td>\n",
        "      <td> 0.013645</td>\n",
        "      <td> 0.930348</td>\n",
        "      <td> 0.042461</td>\n",
        "      <td> 0.203138</td>\n",
        "      <td> 0.113942</td>\n",
        "      <td> 0.203138</td>\n",
        "      <td> 0.132363</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Aberdeen, WA Micro Area</th>\n",
        "      <td>  72797</td>\n",
        "      <td>  59282</td>\n",
        "      <td>   762</td>\n",
        "      <td>  6272</td>\n",
        "      <td>  995</td>\n",
        "      <td> 5486</td>\n",
        "      <td> 0.013668</td>\n",
        "      <td> 0.010467</td>\n",
        "      <td> 0.086157</td>\n",
        "      <td> 0.814347</td>\n",
        "      <td> 0.075360</td>\n",
        "      <td> 0.422324</td>\n",
        "      <td> 0.321742</td>\n",
        "      <td> 0.422324</td>\n",
        "      <td> 0.323441</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Abilene, TX Metro Area</th>\n",
        "      <td> 165252</td>\n",
        "      <td> 112735</td>\n",
        "      <td> 11549</td>\n",
        "      <td> 35108</td>\n",
        "      <td> 2110</td>\n",
        "      <td> 3750</td>\n",
        "      <td> 0.012768</td>\n",
        "      <td> 0.069887</td>\n",
        "      <td> 0.212451</td>\n",
        "      <td> 0.682201</td>\n",
        "      <td> 0.022693</td>\n",
        "      <td> 0.570100</td>\n",
        "      <td> 0.597267</td>\n",
        "      <td> 0.570100</td>\n",
        "      <td> 0.483905</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Ada, OK Micro Area</th>\n",
        "      <td>  37492</td>\n",
        "      <td>  25973</td>\n",
        "      <td>   879</td>\n",
        "      <td>  1523</td>\n",
        "      <td>  244</td>\n",
        "      <td> 8873</td>\n",
        "      <td> 0.006508</td>\n",
        "      <td> 0.023445</td>\n",
        "      <td> 0.040622</td>\n",
        "      <td> 0.692761</td>\n",
        "      <td> 0.236664</td>\n",
        "      <td> 0.525798</td>\n",
        "      <td> 0.282587</td>\n",
        "      <td> 0.525798</td>\n",
        "      <td> 0.461830</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 15 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 82,
       "text": [
        "                           Total   White  Black  Hispanic  Asian  Other  \\\n",
        "Name                                                                      \n",
        "Abbeville, LA Micro Area   57999   46305   8246      1381   1148    919   \n",
        "Aberdeen, SD Micro Area    40602   37774    192       554    358   1724   \n",
        "Aberdeen, WA Micro Area    72797   59282    762      6272    995   5486   \n",
        "Abilene, TX Metro Area    165252  112735  11549     35108   2110   3750   \n",
        "Ada, OK Micro Area         37492   25973    879      1523    244   8873   \n",
        "\n",
        "                           p_Asian   p_Black  p_Hispanic   p_White   p_Other  \\\n",
        "Name                                                                           \n",
        "Abbeville, LA Micro Area  0.019793  0.142175    0.023811  0.798376  0.015845   \n",
        "Aberdeen, SD Micro Area   0.008817  0.004729    0.013645  0.930348  0.042461   \n",
        "Aberdeen, WA Micro Area   0.013668  0.010467    0.086157  0.814347  0.075360   \n",
        "Abilene, TX Metro Area    0.012768  0.069887    0.212451  0.682201  0.022693   \n",
        "Ada, OK Micro Area        0.006508  0.023445    0.040622  0.692761  0.236664   \n",
        "\n",
        "                          entropy5  entropy4  entropy_rice  gini_simpson  \n",
        "Name                                                                      \n",
        "Abbeville, LA Micro Area  0.428364  0.445662      0.428364      0.341173  \n",
        "Aberdeen, SD Micro Area   0.203138  0.113942      0.203138      0.132363  \n",
        "Aberdeen, WA Micro Area   0.422324  0.321742      0.422324      0.323441  \n",
        "Abilene, TX Metro Area    0.570100  0.597267      0.570100      0.483905  \n",
        "Ada, OK Micro Area        0.525798  0.282587      0.525798      0.461830  \n",
        "\n",
        "[5 rows x 15 columns]"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Testing code\n",
      "\n",
      "def to_unicode(vals):\n",
      "    return [unicode(v) for v in vals]\n",
      "\n",
      "def test_msas_df(msas_df):\n",
      "\n",
      "    min_set_of_columns =  set(['Asian','Black','Hispanic', 'Other', 'Total', 'White',\n",
      "     'entropy4', 'entropy5', 'entropy_rice', 'gini_simpson','p_Asian', 'p_Black',\n",
      "     'p_Hispanic', 'p_Other','p_White'])  \n",
      "    \n",
      "    assert min_set_of_columns & set(msas_df.columns) == min_set_of_columns\n",
      "    \n",
      "    # https://www.census.gov/geo/maps-data/data/tallies/national_geo_tallies.html\n",
      "    # 366 metro areas\n",
      "    # 576 micropolitan areas\n",
      "    \n",
      "    assert len(msas_df) == 942  \n",
      "    \n",
      "    # total number of people in metro/micro areas\n",
      "    \n",
      "    assert msas_df.Total.sum() == 289261315\n",
      "    assert msas_df['White'].sum() == 180912856\n",
      "    assert msas_df['Other'].sum() == 8540181\n",
      "    \n",
      "    # list of msas in descendng order by entropy_rice \n",
      "    # calculate the top 10 metros by population\n",
      "    top_10_metros = msas_df.sort_index(by='Total', ascending=False)[:10]\n",
      "    \n",
      "    msa_codes_in_top_10_pop_sorted_by_entropy_rice = list(top_10_metros.sort_index(by='entropy_rice', \n",
      "                                                ascending=False).index) \n",
      "    \n",
      "    assert to_unicode(msa_codes_in_top_10_pop_sorted_by_entropy_rice)== [u'26420', u'35620', u'47900', u'31100', u'19100', \n",
      "        u'33100', u'16980', u'12060', u'37980', u'14460']\n",
      "\n",
      "\n",
      "    top_10_metro = msas_df.sort_index(by='Total', ascending=False)[:10]\n",
      "    \n",
      "    list(top_10_metro.sort_index(by='entropy_rice', ascending=False)['entropy5'])\n",
      "    \n",
      "    np.testing.assert_allclose(top_10_metro.sort_index(by='entropy_rice', ascending=False)['entropy5'], \n",
      "    [0.79628076626851163, 0.80528601550164602, 0.80809418318973791, 0.7980698349711991,\n",
      "     0.75945930510650161, 0.74913610558765376, 0.73683277781032397, 0.72964862063970914,\n",
      "     0.64082509648457675, 0.55697288400004963])\n",
      "    \n",
      "    np.testing.assert_allclose(top_10_metro.sort_index(by='entropy_rice', ascending=False)['entropy_rice'],\n",
      "    [0.87361766576115552,\n",
      "     0.87272877244078051,\n",
      "     0.85931803868749834,\n",
      "     0.85508015237749468,\n",
      "     0.82169723530719896,\n",
      "     0.81953527301129059,\n",
      "     0.80589423784325431,\n",
      "     0.78602596561378812,\n",
      "     0.68611350427640316,\n",
      "     0.56978827050565117])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# you are on the right track if test_msas_df doesn't complain\n",
      "test_msas_df(msas_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AssertionError",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-84-824fb53aa28c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# you are on the right track if test_msas_df doesn't complain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_msas_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsas_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-83-6f5b4c31f134>\u001b[0m in \u001b[0;36mtest_msas_df\u001b[0;34m(msas_df)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     assert to_unicode(msa_codes_in_top_10_pop_sorted_by_entropy_rice)== [u'26420', u'35620', u'47900', u'31100', u'19100', \n\u001b[0;32m---> 34\u001b[0;31m         u'33100', u'16980', u'12060', u'37980', u'14460']\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAssertionError\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# code to save your dataframe to a CSV\n",
      "# upload the CSV to bCourses\n",
      "# uncomment to run\n",
      "msas_df.to_csv(\"msas_2010.csv\", encoding=\"UTF-8\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load back the CSV and test again\n",
      "# df = DataFrame.from_csv(\"msas_2010.csv\", encoding=\"UTF-8\")\n",
      "# test_msas_df(df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    }
   ],
   "metadata": {}
  }
 ]
}